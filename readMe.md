# ğŸ™ï¸ Solana AI Voice Assistant

A Python-based voice assistant that uses Whisper for speech-to-text (STT), a simple agent for response generation, and Deepgram for text-to-speech (TTS) â€” tailored for Solana devs.

## ğŸ”§ Features

- ğŸ¤ Record audio via microphone
- ğŸ“ Transcribe speech using [OpenAI Whisper](https://github.com/openai/whisper)
- ğŸ¤– Respond using a simple rules-based agent (customizable for Solana questions)
- ğŸ”Š Speak responses using [Deepgram TTS](https://developers.deepgram.com/docs/tts/)
- ğŸ” Continuous interaction loop

## ğŸ›  Requirements

- Python 3.10+
- Conda (recommended)
- A Deepgram API key ([get one here](https://console.deepgram.com/signup))

## ğŸ“¦ Installation

```bash
# Clone the repo
git clone https://github.com/your-username/solana-ai-voice-assistant.git
cd solana-ai-voice-assistant

# Create environment
conda create -n solana-voice python=3.10 -y
conda activate solana-voice

# Install dependencies
pip install -r requirements.txt
````

## ğŸ§ª Run the App

```bash
# Add your Deepgram API key to .env
echo "DEEPGRAM_API_KEY=your_api_key_here" > .env

# Run the assistant
python main.py
```

## ğŸ“ File Structure

```
â”œâ”€â”€ main.py              # Main entry point
â”œâ”€â”€ .env                 # Contains your Deepgram API key
â”œâ”€â”€ requirements.txt     # All Python dependencies
â”œâ”€â”€ README.md            # This file
```

## ğŸ§  Example Q\&A

You can ask the assistant things like:

* â€œWhat is a PDA in Solana?â€
* â€œTell me about Anchor framework.â€
* â€œExplain CPI calls.â€

## ğŸ—£ Tech Stack

* Whisper (STT)
* Deepgram SDK (TTS)
* Python (with SoundDevice, NumPy, Playsound, etc.)

## ğŸš€ Future Ideas

* Replace the rules-based agent with a Retrieval-Augmented Generation (RAG) model
* Add live VAD-based continuous listening
* Integrate with Solana CLI or on-chain contract interactions
