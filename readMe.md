# ğŸ™ï¸ Solana AI Voice Assistant

A Python-based voice assistant that uses Whisper for speech-to-text (STT), a simple agent for response generation, and Deepgram for text-to-speech (TTS) â€” tailored for Solana devs.

## ğŸ”§ Features

- ğŸ¤ Record audio via microphone
- ğŸ“ Transcribe speech using [OpenAI Whisper](https://github.com/openai/whisper)
- ğŸ¤– Respond using a simple rules-based agent (customizable for Solana questions)
- ğŸ”Š Speak responses using [Deepgram TTS](https://developers.deepgram.com/docs/tts/)
- ğŸ” Continuous interaction loop

## ğŸ›  Requirements

- Python 3.10+
- Conda (recommended)
- A Deepgram API key ([get one here](https://console.deepgram.com/signup))

## ğŸ“¦ Installation

```bash
# Clone the repo
git clone https://github.com/your-username/solana-ai-voice-assistant.git
cd solana-ai-voice-assistant

# Create environment
conda create -n solana-voice python=3.10 -y
conda activate solana-voice

# Install dependencies
pip install -r requirements.txt
````

## ğŸ§ª Run the App

```bash
# Add your Deepgram API key to .env
echo "DEEPGRAM_API_KEY=your_api_key_here" > .env

# Run the assistant
python main.py
```

## ğŸ“ File Structure

```
voice-agent/
â”œâ”€â”€ .env                         # Environment variables (e.g., API keys)
â”œâ”€â”€ README.md                    # Project overview and setup instructions
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ main.py                      # Main voice assistant loop (record, transcribe, respond, speak)
â”œâ”€â”€ agent/                       # Agent framework
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agent.py                 # Central loader to select active agent
â”‚   â”œâ”€â”€ openai_agent/
â”‚   â”‚   â””â”€â”€ gpt_agent.py         # Uses OpenAI GPT (e.g., GPT-4)
â”‚   â”œâ”€â”€ local_agent/
â”‚   â”‚   â””â”€â”€ local_llm.py         # Talks to local LLMs (e.g., via Ollama)
â”‚   â”œâ”€â”€ rag_agent/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ rag.py               # Retrieval-augmented generation logic
â”‚   â””â”€â”€ genai_agent/
â”‚       â””â”€â”€ genai_agent.py       # Custom GenAI agent implementation
â”‚
â”‚
â”œâ”€â”€ actions/
|_____                       

```

## ğŸ§  Example Q\&A

You can ask the assistant things like:

* â€œWhat is a PDA in Solana?â€
* â€œTell me about Anchor framework.â€
* â€œExplain CPI calls.â€

## ğŸ—£ Tech Stack

* Whisper (STT)
* Deepgram SDK (TTS)
* Python (with SoundDevice, NumPy, Playsound, etc.)

## ğŸš€ Future Ideas

* Replace the rules-based agent with a Retrieval-Augmented Generation (RAG) model
* Add live VAD-based continuous listening
* Integrate with Solana CLI or on-chain contract interactions
